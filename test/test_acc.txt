1---------- hidden units = 200, sigmoid, 1 neuron, 100 batch, 1000 iter, AdaGrad learn_rate=0.02

[0.66, 0.65, 0.48, 0.58, 0.63, 0.52, 0.53, 0.5, 0.61, 0.53, 0.57, 0.5, 0.61, 0.51, 0.6, 0.57, 0.59, 0.51, 0.58, 0.6, 0.51, 0.62, 0.61, 0.58, 0.61, 0.47, 0.63, 0.59, 0.58, 0.51, 0.55, 0.57, 0.5, 0.59, 0.57, 0.61, 0.57, 0.53, 0.62, 0.7, 0.54, 0.63, 0.54, 0.51, 0.6, 0.59, 0.67, 0.61, 0.52, 0.52, 0.56, 0.6, 0.61, 0.59, 0.56, 0.53, 0.48, 0.55, 0.56, 0.58, 0.52, 0.51, 0.56, 0.58, 0.51, 0.5, 0.53, 0.55, 0.47, 0.55, 0.65, 0.57, 0.62, 0.55, 0.56, 0.64, 0.54, 0.53, 0.52, 0.58, 0.62, 0.53, 0.57, 0.55, 0.57, 0.68, 0.59, 0.57, 0.5, 0.66, 0.56, 0.55, 0.56, 0.57, 0.52, 0.45, 0.59, 0.59, 0.59, 0.6]
[0.53, 0.62, 0.61, 0.62, 0.58, 0.61, 0.47, 0.55, 0.56, 0.55, 0.6, 0.53, 0.53, 0.53, 0.55, 0.54, 0.51, 0.55, 0.53, 0.46, 0.52, 0.55, 0.52, 0.5, 0.53, 0.5, 0.42, 0.54, 0.56, 0.4, 0.42, 0.57, 0.61, 0.51, 0.55, 0.44, 0.47, 0.42, 0.53, 0.55, 0.52, 0.5, 0.46, 0.53, 0.6, 0.55, 0.53, 0.55, 0.56, 0.49, 0.52, 0.54, 0.57, 0.48, 0.44, 0.55, 0.62, 0.5, 0.61, 0.56, 0.57, 0.51, 0.55, 0.58, 0.49, 0.45, 0.57, 0.53, 0.65, 0.5, 0.56, 0.5, 0.53, 0.45, 0.56, 0.64, 0.56, 0.56, 0.43, 0.51, 0.5, 0.54, 0.53, 0.55, 0.47, 0.59, 0.53, 0.54, 0.37, 0.54, 0.57, 0.61, 0.61, 0.63, 0.5, 0.56, 0.55, 0.49, 0.52, 0.47]

2---------- hidden units = 50, sigmoid, 1 neuron, 100 batch, 1000 uter, AdaGrad learn_rate=0.02

[0.51, 0.53, 0.54, 0.58, 0.53, 0.56, 0.53, 0.56, 0.59, 0.56, 0.61, 0.59, 0.63, 0.55, 0.56, 0.49, 0.6, 0.56, 0.51, 0.52, 0.55, 0.55, 0.57, 0.53, 0.59, 0.42, 0.52, 0.52, 0.58, 0.61, 0.51, 0.49, 0.51, 0.55, 0.63, 0.54, 0.64, 0.53, 0.61, 0.5, 0.51, 0.54, 0.48, 0.47, 0.61, 0.51, 0.54, 0.54, 0.53, 0.5, 0.57, 0.51, 0.56, 0.57, 0.47, 0.51, 0.56, 0.43, 0.47, 0.45, 0.59, 0.57, 0.56, 0.47, 0.58, 0.5, 0.56, 0.55, 0.51, 0.61, 0.42, 0.61, 0.43, 0.56, 0.54, 0.51, 0.43, 0.63, 0.58, 0.53, 0.57, 0.53, 0.62, 0.61, 0.59, 0.55, 0.54, 0.54, 0.62, 0.5, 0.48, 0.61, 0.5, 0.53, 0.51, 0.5, 0.48, 0.48, 0.53, 0.43]
[0.45, 0.59, 0.47, 0.48, 0.51, 0.5, 0.41, 0.6, 0.49, 0.49, 0.47, 0.46, 0.44, 0.52, 0.49, 0.47, 0.53, 0.58, 0.57, 0.53, 0.54, 0.56, 0.55, 0.53, 0.53, 0.51, 0.51, 0.55, 0.56, 0.5, 0.44, 0.5, 0.67, 0.54, 0.53, 0.61, 0.5, 0.51, 0.54, 0.56, 0.53, 0.5, 0.45, 0.46, 0.5, 0.48, 0.49, 0.54, 0.45, 0.49, 0.56, 0.52, 0.65, 0.57, 0.45, 0.48, 0.47, 0.48, 0.48, 0.55, 0.56, 0.48, 0.52, 0.57, 0.55, 0.54, 0.51, 0.51, 0.5, 0.56, 0.46, 0.52, 0.52, 0.56, 0.52, 0.57, 0.54, 0.63, 0.56, 0.51, 0.55, 0.56, 0.46, 0.46, 0.52, 0.46, 0.61, 0.47, 0.55, 0.44, 0.53, 0.47, 0.56, 0.57, 0.54, 0.47, 0.56, 0.59, 0.59, 0.49]
[0.49, 0.54, 0.5, 0.51, 0.57, 0.53, 0.64, 0.49, 0.46, 0.52, 0.59, 0.45, 0.39, 0.51, 0.56, 0.56, 0.46, 0.5, 0.53, 0.47, 0.46, 0.53, 0.55, 0.47, 0.52, 0.55, 0.55, 0.47, 0.49, 0.41, 0.44, 0.54, 0.49, 0.53, 0.6, 0.5, 0.48, 0.56, 0.6, 0.5, 0.49, 0.56, 0.53, 0.46, 0.57, 0.54, 0.48, 0.55, 0.42, 0.52, 0.48, 0.58, 0.48, 0.48, 0.52, 0.53, 0.51, 0.55, 0.53, 0.52, 0.54, 0.52, 0.49, 0.49, 0.5, 0.51, 0.49, 0.53, 0.48, 0.53, 0.48, 0.55, 0.51, 0.56, 0.52, 0.54, 0.56, 0.54, 0.53, 0.61, 0.59, 0.54, 0.54, 0.46, 0.54, 0.53, 0.59, 0.48, 0.46, 0.55, 0.51, 0.47, 0.55, 0.55, 0.53, 0.57, 0.5, 0.56, 0.45, 0.49]
[0.6, 0.48, 0.54, 0.52, 0.51, 0.57, 0.46, 0.49, 0.52, 0.53, 0.59, 0.53, 0.56, 0.55, 0.56, 0.47, 0.56, 0.51, 0.57, 0.52, 0.54, 0.54, 0.55, 0.56, 0.46, 0.55, 0.48, 0.62, 0.5, 0.5, 0.47, 0.62, 0.49, 0.51, 0.5, 0.59, 0.51, 0.55, 0.57, 0.49, 0.51, 0.44, 0.45, 0.5, 0.54, 0.54, 0.58, 0.49, 0.53, 0.5, 0.57, 0.47, 0.46, 0.53, 0.45, 0.58, 0.43, 0.55, 0.42, 0.52, 0.48, 0.55, 0.5, 0.54, 0.54, 0.57, 0.53, 0.56, 0.52, 0.57, 0.51, 0.51, 0.54, 0.65, 0.49, 0.6, 0.47, 0.45, 0.58, 0.52, 0.6, 0.54, 0.5, 0.51, 0.55, 0.63, 0.52, 0.54, 0.5, 0.47, 0.51, 0.54, 0.53, 0.51, 0.52, 0.51, 0.5, 0.51, 0.53, 0.57]
[0.56, 0.55, 0.58, 0.53, 0.58, 0.52, 0.43, 0.55, 0.53, 0.58, 0.5, 0.57, 0.51, 0.67, 0.57, 0.54, 0.55, 0.47, 0.58, 0.52, 0.61, 0.5, 0.63, 0.51, 0.48, 0.61, 0.47, 0.64, 0.47, 0.45, 0.51, 0.59, 0.55, 0.54, 0.43, 0.48, 0.4, 0.44, 0.5, 0.53, 0.48, 0.55, 0.47, 0.62, 0.52, 0.53, 0.5, 0.54, 0.6, 0.55, 0.59, 0.52, 0.53, 0.57, 0.52, 0.54, 0.54, 0.59, 0.55, 0.51, 0.5, 0.49, 0.59, 0.46, 0.47, 0.5, 0.54, 0.58, 0.46, 0.57, 0.59, 0.59, 0.51, 0.56, 0.58, 0.57, 0.57, 0.56, 0.51, 0.57, 0.57, 0.62, 0.48, 0.57, 0.58, 0.54, 0.51, 0.51, 0.59, 0.58, 0.55, 0.5, 0.61, 0.5, 0.52, 0.5, 0.52, 0.49, 0.63, 0.62]


3----------------- hidden units = 50, softmax, 2 neurons, 100 batch, 1000 iter, AdaGrad learn_rate=0.02

[0.4, 0.48, 0.56, 0.54, 0.48, 0.56, 0.52, 0.56, 0.49, 0.54, 0.59, 0.54, 0.44, 0.46, 0.52, 0.45, 0.47, 0.55, 0.57, 0.48, 0.52, 0.53, 0.55, 0.51, 0.49, 0.47, 0.54, 0.52, 0.54, 0.53, 0.47, 0.52, 0.47, 0.52, 0.55, 0.46, 0.57, 0.49, 0.6, 0.51, 0.47, 0.53, 0.58, 0.49, 0.51, 0.5, 0.52, 0.53, 0.47, 0.48, 0.46, 0.5, 0.6, 0.51, 0.51, 0.49, 0.51, 0.52, 0.49, 0.45, 0.55, 0.53, 0.46, 0.51, 0.5, 0.49, 0.47, 0.44, 0.52, 0.45, 0.47, 0.59, 0.54, 0.52, 0.51, 0.59, 0.6, 0.58, 0.61, 0.54, 0.54, 0.52, 0.54, 0.47, 0.44, 0.48, 0.49, 0.44, 0.5, 0.47, 0.55, 0.52, 0.58, 0.51, 0.47, 0.44, 0.43, 0.47, 0.48, 0.54]
[0.55, 0.52, 0.48, 0.47, 0.47, 0.45, 0.56, 0.48, 0.44, 0.55, 0.49, 0.5, 0.49, 0.5, 0.53, 0.55, 0.54, 0.5, 0.52, 0.47, 0.52, 0.52, 0.51, 0.49, 0.5, 0.42, 0.52, 0.48, 0.47, 0.42, 0.53, 0.57, 0.53, 0.48, 0.5, 0.46, 0.48, 0.48, 0.54, 0.49, 0.46, 0.5, 0.51, 0.54, 0.45, 0.48, 0.53, 0.52, 0.44, 0.48, 0.45, 0.48, 0.51, 0.63, 0.56, 0.5, 0.5, 0.5, 0.58, 0.51, 0.51, 0.47, 0.48, 0.61, 0.51, 0.56, 0.46, 0.55, 0.45, 0.48, 0.57, 0.59, 0.5, 0.53, 0.49, 0.48, 0.51, 0.49, 0.45, 0.56, 0.42, 0.43, 0.64, 0.52, 0.58, 0.47, 0.53, 0.47, 0.42, 0.49, 0.56, 0.5, 0.41, 0.55, 0.54, 0.52, 0.52, 0.46, 0.54, 0.43]
[0.46, 0.45, 0.54, 0.45, 0.4, 0.46, 0.48, 0.58, 0.56, 0.51, 0.47, 0.47, 0.48, 0.53, 0.5, 0.54, 0.47, 0.57, 0.53, 0.52, 0.48, 0.46, 0.42, 0.48, 0.45, 0.41, 0.49, 0.5, 0.41, 0.51, 0.48, 0.47, 0.51, 0.5, 0.44, 0.54, 0.46, 0.51, 0.47, 0.55, 0.46, 0.52, 0.35, 0.48, 0.48, 0.44, 0.42, 0.53, 0.51, 0.47, 0.47, 0.49, 0.43, 0.56, 0.51, 0.52, 0.5, 0.61, 0.49, 0.45, 0.46, 0.42, 0.43, 0.51, 0.44, 0.5, 0.48, 0.51, 0.53, 0.53, 0.47, 0.46, 0.5, 0.48, 0.4, 0.5, 0.49, 0.48, 0.46, 0.45, 0.5, 0.54, 0.46, 0.49, 0.49, 0.47, 0.47, 0.54, 0.44, 0.52, 0.55, 0.5, 0.48, 0.38, 0.57, 0.44, 0.46, 0.45, 0.5, 0.47]
[0.47, 0.5, 0.51, 0.35, 0.52, 0.38, 0.47, 0.5, 0.46, 0.43, 0.46, 0.57, 0.42, 0.43, 0.42, 0.39, 0.49, 0.51, 0.4, 0.44, 0.58, 0.49, 0.48, 0.45, 0.53, 0.51, 0.56, 0.42, 0.5, 0.46, 0.43, 0.47, 0.43, 0.52, 0.35, 0.47, 0.44, 0.51, 0.52, 0.5, 0.48, 0.51, 0.5, 0.47, 0.46, 0.44, 0.45, 0.48, 0.46, 0.43, 0.49, 0.45, 0.47, 0.46, 0.58, 0.39, 0.38, 0.48, 0.52, 0.43, 0.49, 0.41, 0.43, 0.47, 0.44, 0.47, 0.47, 0.49, 0.44, 0.38, 0.52, 0.44, 0.51, 0.47, 0.38, 0.47, 0.46, 0.56, 0.45, 0.45, 0.48, 0.4, 0.43, 0.37, 0.37, 0.33, 0.48, 0.42, 0.45, 0.48, 0.47, 0.45, 0.54, 0.39, 0.4, 0.46, 0.44, 0.51, 0.41, 0.47]
[0.38, 0.54, 0.47, 0.46, 0.47, 0.48, 0.47, 0.48, 0.43, 0.48, 0.45, 0.46, 0.49, 0.55, 0.46, 0.45, 0.5, 0.46, 0.39, 0.48, 0.39, 0.48, 0.45, 0.43, 0.56, 0.5, 0.46, 0.53, 0.47, 0.49, 0.54, 0.45, 0.48, 0.53, 0.43, 0.49, 0.53, 0.4, 0.48, 0.51, 0.57, 0.48, 0.5, 0.55, 0.43, 0.51, 0.5, 0.48, 0.52, 0.52, 0.5, 0.56, 0.41, 0.47, 0.45, 0.45, 0.46, 0.5, 0.42, 0.44, 0.41, 0.45, 0.5, 0.45, 0.53, 0.44, 0.47, 0.45, 0.53, 0.53, 0.62, 0.47, 0.47, 0.53, 0.54, 0.46, 0.56, 0.5, 0.49, 0.52, 0.54, 0.49, 0.45, 0.51, 0.41, 0.6, 0.42, 0.54, 0.58, 0.47, 0.49, 0.44, 0.46, 0.47, 0.55, 0.53, 0.46, 0.52, 0.47, 0.54]


4----------------- hidden units = 50, softmax, 2 neurons, 100 batch, 1000 iter, AdaGrad learn_rate=0.1


[0.48, 0.54, 0.44, 0.37, 0.51, 0.43, 0.5, 0.47, 0.53, 0.49, 0.44, 0.52, 0.55, 0.43, 0.43, 0.58, 0.49, 0.55, 0.51, 0.45, 0.41, 0.44, 0.52, 0.52, 0.57, 0.49, 0.47, 0.49, 0.43, 0.5, 0.43, 0.47, 0.57, 0.49, 0.45, 0.52, 0.5, 0.49, 0.48, 0.42, 0.46, 0.51, 0.47, 0.48, 0.56, 0.52, 0.47, 0.46, 0.48, 0.54, 0.44, 0.54, 0.51, 0.57, 0.49, 0.5, 0.49, 0.37, 0.59, 0.41, 0.46, 0.56, 0.57, 0.49, 0.51, 0.4, 0.46, 0.56, 0.55, 0.53, 0.48, 0.52, 0.52, 0.39, 0.55, 0.47, 0.49, 0.53, 0.53, 0.54, 0.57, 0.52, 0.43, 0.46, 0.41, 0.46, 0.48, 0.48, 0.41, 0.45, 0.45, 0.45, 0.41, 0.44, 0.47, 0.45, 0.61, 0.53, 0.49, 0.53]
[0.57, 0.54, 0.43, 0.56, 0.48, 0.53, 0.56, 0.49, 0.4, 0.51, 0.46, 0.48, 0.54, 0.54, 0.58, 0.55, 0.54, 0.54, 0.52, 0.52, 0.61, 0.38, 0.42, 0.49, 0.56, 0.56, 0.58, 0.51, 0.54, 0.49, 0.57, 0.53, 0.49, 0.45, 0.54, 0.5, 0.5, 0.55, 0.55, 0.56, 0.53, 0.53, 0.54, 0.5, 0.46, 0.53, 0.5, 0.54, 0.59, 0.55, 0.48, 0.44, 0.43, 0.49, 0.49, 0.53, 0.51, 0.57, 0.59, 0.44, 0.51, 0.52, 0.54, 0.36, 0.5, 0.47, 0.53, 0.54, 0.5, 0.51, 0.58, 0.57, 0.49, 0.51, 0.55, 0.6, 0.49, 0.46, 0.44, 0.49, 0.51, 0.51, 0.52, 0.46, 0.43, 0.49, 0.57, 0.54, 0.5, 0.59, 0.53, 0.49, 0.56, 0.45, 0.44, 0.54, 0.59, 0.51, 0.49, 0.46]
[0.52, 0.46, 0.46, 0.46, 0.41, 0.53, 0.47, 0.39, 0.44, 0.5, 0.46, 0.46, 0.51, 0.43, 0.5, 0.43, 0.45, 0.37, 0.4, 0.5, 0.51, 0.38, 0.46, 0.45, 0.49, 0.46, 0.43, 0.37, 0.43, 0.55, 0.48, 0.43, 0.47, 0.49, 0.57, 0.43, 0.48, 0.52, 0.5, 0.41, 0.45, 0.6, 0.58, 0.47, 0.48, 0.45, 0.48, 0.5, 0.41, 0.44, 0.4, 0.5, 0.44, 0.42, 0.56, 0.48, 0.55, 0.37, 0.39, 0.47, 0.44, 0.37, 0.32, 0.52, 0.4, 0.48, 0.46, 0.44, 0.48, 0.53, 0.42, 0.51, 0.38, 0.46, 0.44, 0.42, 0.54, 0.46, 0.53, 0.47, 0.46, 0.37, 0.49, 0.51, 0.4, 0.46, 0.51, 0.47, 0.55, 0.44, 0.47, 0.49, 0.58, 0.47, 0.45, 0.51, 0.47, 0.4, 0.4, 0.38]
[0.6, 0.6, 0.45, 0.47, 0.56, 0.55, 0.48, 0.45, 0.58, 0.49, 0.43, 0.45, 0.45, 0.51, 0.45, 0.52, 0.49, 0.55, 0.45, 0.54, 0.44, 0.49, 0.48, 0.52, 0.52, 0.5, 0.55, 0.47, 0.42, 0.47, 0.52, 0.44, 0.5, 0.52, 0.52, 0.56, 0.49, 0.52, 0.51, 0.59, 0.48, 0.53, 0.56, 0.53, 0.39, 0.4, 0.45, 0.5, 0.55, 0.5, 0.5, 0.45, 0.45, 0.42, 0.53, 0.45, 0.54, 0.48, 0.5, 0.55, 0.58, 0.57, 0.53, 0.4, 0.51, 0.47, 0.57, 0.52, 0.57, 0.48, 0.51, 0.53, 0.49, 0.43, 0.41, 0.42, 0.49, 0.42, 0.47, 0.46, 0.39, 0.49, 0.59, 0.46, 0.61, 0.51, 0.54, 0.54, 0.51, 0.59, 0.51, 0.62, 0.48, 0.43, 0.63, 0.49, 0.44, 0.55, 0.59, 0.45]
[0.46, 0.45, 0.45, 0.5, 0.45, 0.46, 0.6, 0.52, 0.49, 0.54, 0.55, 0.55, 0.41, 0.44, 0.47, 0.57, 0.42, 0.47, 0.51, 0.38, 0.45, 0.48, 0.45, 0.47, 0.56, 0.4, 0.44, 0.41, 0.46, 0.55, 0.49, 0.52, 0.51, 0.48, 0.48, 0.51, 0.4, 0.55, 0.46, 0.52, 0.5, 0.44, 0.54, 0.45, 0.46, 0.58, 0.56, 0.54, 0.59, 0.51, 0.47, 0.48, 0.58, 0.49, 0.59, 0.49, 0.46, 0.43, 0.53, 0.48, 0.56, 0.53, 0.59, 0.48, 0.47, 0.46, 0.5, 0.46, 0.51, 0.49, 0.54, 0.55, 0.47, 0.45, 0.64, 0.49, 0.48, 0.55, 0.47, 0.59, 0.45, 0.51, 0.46, 0.46, 0.48, 0.56, 0.52, 0.53, 0.52, 0.57, 0.55, 0.51, 0.51, 0.51, 0.52, 0.45, 0.46, 0.47, 0.51, 0.51]


5------------------BATCH CHANGE, hidden units = 50, softmax, 2 neurons, 100 batch, 1000 iter, AdaGrad learn_rate=0.1


[0.73, 0.0, 0.31, 0.4, 0.7, 0.75, 0.71, 0.5, 0.66, 0.4, 0.0, 0.38, 0.46, 0.41, 0.0, 0.0, 0.72, 0.36, 0.74, 0.0, 0.85, 0.0, 0.74, 0.67, 0.88, 0.77, 0.7, 0.0, 0.45, 0.79, 0.72, 0.0, 0.79, 0.86, 0.46, 0.69, 0.73, 0.75, 0.5, 0.82, 0.46, 0.64, 0.43, 0.76, 0.0, 0.68, 0.37, 0.0, 0.85, 0.37, 0.74, 0.4, 0.43, 0.59, 0.49, 0.3, 0.81, 0.37, 0.83, 0.84, 0.38, 0.0, 0.71, 0.31, 0.52, 0.78, 0.66, 0.69, 0.39, 0.67, 0.0, 0.34, 0.74, 0.44, 0.79, 0.63, 0.0, 0.69, 0.76, 0.33, 0.0, 0.75, 0.38, 0.76, 0.0, 0.45, 0.83, 0.75, 0.83, 0.67, 0.42, 0.37, 0.0, 0.8, 0.85, 0.79, 0.86, 0.82, 0.71, 0.72]
[0.75, 1.0, 1.0, 0.53, 0.65, 0.55, 1.0, 0.0, 0.59, 0.41, 0.52, 1.0, 0.35, 0.62, 0.61, 0.43, 0.69, 0.0, 0.7, 1.0, 0.71, 0.74, 1.0, 0.66, 0.59, 0.0, 0.71, 0.52, 0.66, 0.0, 0.5, 0.68, 0.73, 0.0, 0.49, 0.31, 0.84, 0.6, 0.72, 0.49, 0.54, 0.0, 1.0, 1.0, 0.28, 0.55, 0.6, 0.0, 0.43, 0.69, 0.68, 0.66, 0.37, 0.78, 0.75, 0.56, 0.74, 0.5, 1.0, 0.72, 0.59, 0.64, 0.68, 0.64, 0.68, 0.6, 0.8, 1.0, 0.41, 0.37, 0.76, 1.0, 0.41, 0.0, 0.78, 0.35, 0.43, 0.48, 0.63, 0.44, 0.36, 0.25, 0.71, 1.0, 0.65, 0.66, 0.82, 0.67, 0.58, 0.43, 0.0, 1.0, 0.44, 0.0, 0.83, 0.78, 1.0, 0.69, 0.54, 0.27]
[0.64, 0.8, 0.26, 0.83, 0.45, 0.67, 0.69, 0.4, 0.0, 0.0, 0.57, 0.0, 0.0, 0.62, 0.0, 0.75, 0.66, 0.78, 0.72, 0.69, 0.0, 0.79, 0.72, 0.74, 0.66, 0.0, 0.73, 0.34, 0.0, 0.66, 0.73, 0.34, 0.66, 0.0, 0.68, 0.72, 0.81, 0.4, 0.0, 0.0, 0.41, 0.0, 0.82, 0.43, 0.0, 0.41, 0.64, 0.7, 0.34, 0.0, 0.78, 0.71, 0.6, 0.74, 0.75, 0.35, 0.0, 0.79, 0.41, 0.81, 0.69, 0.0, 0.0, 0.62, 0.36, 0.45, 0.3, 0.76, 0.75, 0.0, 0.28, 0.64, 0.73, 0.0, 0.35, 0.66, 0.4, 0.8, 0.5, 0.78, 0.0, 0.82, 0.0, 0.0, 0.73, 0.32, 0.6, 0.66, 0.69, 0.7, 0.28, 0.74, 0.68, 0.8, 0.77, 0.4, 0.0, 0.3, 0.0, 0.78]
[0.67, 0.42, 0.29, 0.08, 0.25, 0.0, 0.59, 0.69, 0.0, 0.55, 0.0, 0.45, 0.0, 0.91, 0.0, 0.78, 0.32, 0.77, 0.0, 0.0, 0.75, 0.54, 0.73, 0.0, 0.66, 0.7, 0.0, 0.0, 0.0, 0.7, 0.5, 0.6, 0.0, 0.0, 0.81, 0.0, 0.27, 0.31, 0.69, 0.85, 0.0, 0.14, 0.28, 0.62, 0.81, 0.72, 0.49, 0.0, 0.0, 0.35, 0.19, 0.34, 0.66, 0.66, 0.0, 0.65, 0.51, 0.0, 0.66, 0.0, 0.0, 0.39, 0.7, 0.36, 0.66, 0.53, 0.65, 0.78, 0.63, 0.0, 0.47, 0.0, 0.0, 0.67, 0.37, 0.76, 0.38, 0.79, 0.7, 0.0, 0.67, 0.88, 0.59, 0.72, 0.64, 0.0, 0.0, 0.76, 0.71, 0.67, 0.3, 0.1, 0.64, 0.56, 0.0, 0.44, 0.8, 0.0, 0.79, 0.67]
[0.69, 0.45, 0.8, 0.4, 0.58, 0.42, 0.79, 0.0, 0.72, 0.35, 0.0, 0.0, 0.0, 0.0, 0.71, 0.26, 0.74, 0.61, 0.82, 0.0, 0.51, 0.84, 0.0, 0.39, 0.7, 0.49, 0.4, 0.81, 0.71, 0.77, 0.0, 0.43, 0.38, 0.27, 0.74, 0.43, 0.48, 0.71, 0.71, 0.82, 0.54, 0.63, 0.65, 0.27, 0.37, 0.0, 0.0, 0.77, 0.82, 0.85, 0.78, 0.64, 0.72, 0.37, 0.0, 0.36, 0.48, 0.34, 0.0, 0.64, 0.76, 0.73, 0.0, 0.4, 0.77, 0.8, 0.0, 0.49, 0.79, 0.76, 0.39, 0.46, 0.45, 0.64, 0.32, 0.41, 0.72, 0.68, 0.0, 0.76, 0.0, 0.25, 0.65, 0.0, 0.54, 0.33, 0.72, 0.0, 0.74, 0.52, 0.72, 0.73, 0.33, 0.65, 0.34, 0.8, 0.44, 0.65, 0.45, 0.32]

6------------------BATCH CHANGE 2k iter, hidden units = 50, softmax, 2 neurons, 100 batch, 1000 iter, AdaGrad learn_rate=0.1


[0.48, 0.0, 0.66, 0.62, 0.74, 0.45, 1.0, 0.75, 0.0, 1.0, 0.74, 0.0, 0.79, 0.0, 0.74, 0.71, 0.0, 0.43, 0.42, 0.42, 0.69, 0.8, 0.0, 0.0, 0.63, 0.73, 0.59, 0.37, 0.71, 0.4, 0.32, 0.74, 0.79, 1.0, 1.0, 0.55, 0.74, 0.0, 0.79, 0.0, 0.41, 0.7, 0.77, 0.0, 0.78, 0.39, 0.0, 0.0, 0.6, 0.47, 0.89, 0.44, 0.0, 0.7, 0.7, 0.43, 0.0, 0.0, 0.0, 0.83, 0.81, 0.61, 0.57, 0.69, 0.34, 0.24, 0.39, 0.53, 0.77, 0.58, 0.63, 0.71, 0.76, 0.56, 0.0, 0.0, 0.79, 0.72, 0.0, 0.26, 0.61, 0.52, 0.7, 0.64, 0.47, 0.0, 1.0, 0.0, 0.7, 0.78, 0.83, 0.67, 0.57, 0.64, 0.56, 0.73, 0.77, 0.43, 1.0, 0.62]
[0.69, 0.77, 0.22, 0.72, 0.38, 0.4, 0.65, 0.75, 0.34, 0.8, 0.79, 0.64, 0.0, 0.6, 0.71, 0.81, 0.8, 0.0, 0.49, 0.79, 0.72, 0.66, 0.31, 0.0, 0.0, 0.72, 0.0, 1.0, 0.87, 0.0, 0.75, 0.3, 0.0, 0.37, 0.76, 0.7, 1.0, 0.31, 0.68, 1.0, 0.67, 0.0, 0.0, 0.41, 0.6, 0.73, 0.36, 0.58, 0.73, 0.0, 0.53, 0.75, 0.18, 0.31, 0.75, 1.0, 0.33, 0.0, 0.69, 0.68, 0.47, 0.0, 0.62, 0.0, 0.45, 0.36, 0.12, 0.42, 0.15, 0.61, 0.75, 0.7, 0.8, 0.37, 0.0, 0.71, 0.68, 0.56, 0.46, 1.0, 0.75, 0.46, 0.0, 0.72, 0.69, 0.39, 0.65, 0.85, 0.7, 0.62, 0.42, 0.0, 0.37, 0.37, 0.79, 0.79, 0.62, 0.37, 0.64, 0.37]
[0.0, 0.82, 0.68, 0.74, 0.42, 0.0, 0.72, 0.81, 0.35, 0.79, 0.74, 0.0, 0.37, 0.39, 0.4, 0.78, 0.73, 0.68, 0.63, 0.76, 0.28, 0.0, 0.0, 0.67, 0.0, 0.73, 0.0, 0.41, 0.0, 0.0, 0.39, 0.25, 0.0, 0.68, 0.82, 0.65, 0.41, 0.0, 0.69, 0.8, 0.41, 0.0, 0.0, 0.85, 0.0, 0.0, 0.0, 0.68, 0.43, 0.66, 0.77, 0.35, 0.0, 0.71, 0.76, 0.7, 0.75, 0.0, 0.78, 0.73, 0.81, 0.68, 0.0, 0.28, 0.35, 0.0, 0.74, 0.36, 0.0, 0.39, 0.78, 0.71, 0.0, 0.78, 0.46, 0.71, 0.0, 0.32, 0.8, 0.0, 0.45, 0.81, 0.6, 0.31, 0.43, 0.78, 0.64, 0.73, 0.76, 0.64, 0.0, 0.48, 0.67, 0.0, 0.65, 0.0, 0.0, 0.59, 0.0, 0.36]
[0.0, 0.76, 0.78, 0.73, 0.69, 0.0, 0.0, 0.0, 0.79, 0.74, 0.79, 0.41, 0.71, 0.36, 0.0, 0.8, 0.5, 0.84, 0.4, 0.38, 0.0, 0.67, 0.77, 0.0, 0.7, 0.41, 0.63, 0.0, 0.37, 0.0, 0.5, 0.82, 0.79, 0.79, 0.46, 0.5, 0.42, 0.75, 0.34, 0.39, 0.77, 0.72, 0.0, 0.45, 0.46, 0.76, 0.39, 0.0, 0.49, 0.69, 0.73, 0.0, 0.31, 0.65, 0.75, 0.45, 0.79, 0.0, 0.8, 0.7, 0.71, 0.54, 0.0, 0.77, 0.0, 0.0, 0.23, 0.72, 0.0, 0.41, 0.0, 0.34, 0.38, 0.67, 0.69, 0.66, 0.69, 0.42, 0.7, 0.76, 0.74, 0.0, 0.79, 0.47, 0.77, 0.74, 0.0, 0.75, 0.0, 0.0, 0.49, 0.38, 0.77, 0.79, 0.66, 0.39, 0.36, 0.0, 0.39, 0.52]
[0.79, 0.0, 0.0, 0.68, 0.4, 0.69, 0.56, 0.73, 0.59, 0.0, 0.44, 0.83, 0.37, 0.0, 0.8, 0.0, 0.0, 0.39, 0.32, 0.0, 0.78, 0.47, 0.3, 0.62, 0.52, 0.0, 0.3, 0.0, 0.37, 0.53, 0.37, 0.79, 0.65, 0.76, 0.37, 0.0, 0.43, 0.0, 0.63, 0.7, 0.68, 0.77, 0.45, 0.48, 0.0, 0.0, 0.65, 0.68, 0.56, 0.57, 0.0, 0.41, 0.55, 0.34, 0.0, 0.67, 0.0, 0.76, 0.78, 0.73, 0.0, 0.36, 0.57, 0.73, 0.0, 0.42, 0.81, 0.7, 0.37, 0.78, 0.84, 0.37, 0.65, 0.76, 0.0, 0.73, 0.41, 0.0, 0.83, 0.0, 0.73, 0.41, 0.85, 0.0, 0.79, 0.61, 0.55, 0.62, 0.71, 0.31, 0.48, 0.72, 0.35, 0.83, 0.48, 0.77, 0.46, 0.43, 0.72, 0.54]



